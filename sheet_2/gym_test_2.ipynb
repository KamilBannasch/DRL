{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left\n",
      "O A O B O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O X O O O\n",
      "Total Reward: 10\n",
      "\n",
      "\n",
      "Left\n",
      "O A O B O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O X O O O\n",
      "Total Reward: 10\n",
      "\n",
      "\n",
      "Right\n",
      "O A O B O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O X O O O\n",
      "Total Reward: 10\n",
      "\n",
      "\n",
      "Up\n",
      "O A O B O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O O O O O\n",
      "O X O O O\n",
      "Total Reward: 10\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GridWorldEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(GridWorldEnv, self).__init__()\n",
    "\n",
    "        # Define the grid size and the starting position\n",
    "        self.grid_size = (5, 5)\n",
    "        self.start_state = (0, 1)  # center\n",
    "        self.state = self.start_state\n",
    "\n",
    "        # action space: 0 - move_up, 1 move_right, 2 - move_down, 3 - move_left\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # observation space: states as coordinates in the grid\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(self.grid_size[0]),\n",
    "            spaces.Discrete(self.grid_size[1])\n",
    "        ))\n",
    "\n",
    "        # Set done as false, since we don't have a specific condition on when to terminate the program\n",
    "        self.done = False\n",
    "        \n",
    "        # Get the reward for all the actions taken up until now\n",
    "        self.total_reward = 0\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        reset the environment to the start space. Prepares for a new episode.\n",
    "        \"\"\"\n",
    "        self.state = self.start_state  # Set the state back to the start space as initiated in the __init__ function\n",
    "        self.done = False  # Reset the \"done\" flag to false. Is not needed in this implementation, since done is always false. But could be useful for other implementations\n",
    "        self.total_reward = 0  # Reset the accumulated reward to 0, since we want to reset everything.\n",
    "\n",
    "        # returns the state and the dictionary with the information. Right now no information is given in the dictionary, but that could be changed later ...\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        executes a step. return the next state, the reward, the done flag (as false, like always), the truncated status (should also be false) and the info (which is empty right now)\n",
    "        Führt eine Aktion aus und gibt die nächste Beobachtung, Belohnung, `done`-Status, `truncated`-Status und `info` zurück.\n",
    "        \"\"\"\n",
    "        # Extrahiere die aktuelle Position\n",
    "        y, x = self.state\n",
    "\n",
    "        reward = 0\n",
    "        # Berechne die gewünschte neue Position basierend auf der Aktion (0=oben, 1=rechts, 2=unten, 3=links)\n",
    "        if action == 0:  # up\n",
    "            print(\"Up\")\n",
    "            new_x, new_y = x, y - 1\n",
    "        elif action == 1:  # right\n",
    "            print(\"Right\")\n",
    "            new_x, new_y = x + 1, y\n",
    "        elif action == 2:  # down\n",
    "            print(\"Down\")\n",
    "            new_x, new_y = x, y + 1\n",
    "        elif action == 3:  # left\n",
    "            print(\"Left\")\n",
    "            new_x, new_y = x - 1, y\n",
    "        else:\n",
    "            raise ValueError(\"Ungültige Aktion.\")\n",
    "\n",
    "        # Prüfen, ob die neue Position innerhalb des Grids liegt\n",
    "        if 0 <= new_x < self.grid_size[0] and 0 <= new_y < self.grid_size[1]:\n",
    "            # Prüfen auf Sprünge bei Zielpositionen\n",
    "            if self.state == (0, 1):  # A\n",
    "                reward = 10\n",
    "                self.state = (4, 1)  # Springt zur neuen Position\n",
    "            elif self.state == (0, 3):  # B\n",
    "                reward = 5\n",
    "                self.state = (2, 3)  # Springt zur neuen Position\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            # Update des Zustands\n",
    "            self.state = (new_x, new_y)\n",
    "            \n",
    "            # Wenn die Aktion versucht, das Grid zu verlassen, negative Belohnung\n",
    "            reward = -1\n",
    "        # Füge die Belohnung zur totalen Belohnung hinzu\n",
    "        self.total_reward += reward\n",
    "\n",
    "        # Abschlussbedingung (hier nur als Platzhalter, falls weitere Logik gewünscht ist)\n",
    "        self.done = False\n",
    "\n",
    "        # `truncated` auf False setzen, da keine spezifische Abbruchbedingung vorhanden\n",
    "        truncated = False\n",
    "\n",
    "        # Info-Dictionary\n",
    "        info = {\"total_reward\": self.total_reward}\n",
    "\n",
    "        # Rückgabe des Ergebnisses\n",
    "        return self.state, reward, self.done, truncated, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        \"\"\"\n",
    "        Visualisiert den aktuellen Zustand der Umgebung.\n",
    "        Wenn mode='human', wird der Zustand in der Konsole als Text ausgegeben.\n",
    "        \"\"\"\n",
    "        # Erstelle ein leeres Grid mit 'O'\n",
    "        grid = [[\"O\" for _ in range(self.grid_size[1])] for _ in range(self.grid_size[0])]\n",
    "\n",
    "        # Positioniere den Agenten im Grid\n",
    "        x, y = self.state\n",
    "        \n",
    "\n",
    "        # Definiere spezielle Positionen\n",
    "        grid[0][1] = \"A\"  # Ziel bei (1,0) mit Belohnung von 10\n",
    "        grid[0][3] = \"B\"  # Ziel bei (3,0) mit Belohnung von 5\n",
    "\n",
    "        grid[x][y] = \"X\"  # Setze das aktuelle Feld auf 'X'\n",
    "\n",
    "        # Gebe das Grid in der Konsole aus\n",
    "        print(\"\\n\".join([\" \".join(row) for row in grid]))\n",
    "        print(f\"Total Reward: {self.total_reward}\")  # Ausgabe der akkumulierten Belohnung\n",
    "        print(\"\\n\")  # Leerzeile für bessere Lesbarkeit\n",
    "\n",
    "# Registrierung der Umgebung\n",
    "gym.envs.registration.register(\n",
    "    id='GridWorld-v0',\n",
    "    entry_point='__main__:GridWorldEnv',\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Instanziere die Umgebung\n",
    "    env = gym.make('GridWorld-v0')\n",
    "\n",
    "    # Simuliere eine Episode\n",
    "    state, _ = env.reset()  # Hier wird die geänderte reset-Methode verwendet\n",
    "    frames = []  # Liste zur Speicherung der Frames für die Darstellung\n",
    "\n",
    "    for _ in range(4):  # Führe 4 Schritte aus\n",
    "        action = env.action_space.sample()  # Zufällige Aktion auswählen\n",
    "        next_state, reward, done, truncated, info = env.step(action)  # Schritt ausführen\n",
    "        env.render()  # Zustand rendern\n",
    "        \n",
    "        # Zugriff auf den Zustand der zugrunde liegenden Umgebung\n",
    "        frames.append(env.unwrapped.state)  # Speichere den aktuellen Zustand als Frame\n",
    "\n",
    "    # Optional: Plotten der Frames\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, frame in enumerate(frames):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(np.zeros((5, 5)), cmap='gray', vmin=0, vmax=2)\n",
    "        plt.title(f'Step {i + 1}')\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        plt.text(frame[1], frame[0], 'X', ha='center', va='center', fontsize=20, color='red')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
